# üê∂üê± Dogs vs Cats Classifier ‚Äì Progetto AI
## Progetto per il corso di Laboratorio di ottimizzazione, intelligenza artificiale e machine learning, realizzato da Naman Bagga il 08/01/2026.
Un progetto completo per la classificazione di immagini di cani e gatti tramite reti neurali convoluzionali (CNN) e transfer learning con ResNet18.  
Include addestramento, validazione, logging avanzato, resume training, predizione e confronto dei modelli.

---

## üìå Caratteristiche principali

### ‚úîÔ∏è Modelli implementati
- **SimpleCNN** ‚Äì rete neurale progettata da zero  
- **ResNet18** ‚Äì rete pre-addestrata tramite transfer learning

### ‚úîÔ∏è Funzionalit√† del sistema
- Dataset loader con trasformazioni e normalizzazione
- Early stopping avanzato (monitor accuracy/loss + target accuracy)
- Resume training automatico dai checkpoint
- Salvataggio automatico:
  - Checkpoint per epoca
  - `best_model.pth`
- TensorBoard logging:
  - Loss / Accuracy
  - Confusion Matrix
  - Architettura del modello
  - Immagini del dataset

### ‚úîÔ∏è Modalit√† operative
- `train` ‚Äì Addestra il modello
- `eval` ‚Äì Valuta il modello migliore
- `predict` ‚Äì Predice classe di un'immagine singola
- `resume` ‚Äì Riprende il training dall‚Äôultimo checkpoint

---

## üìÇ Struttura del progetto
```
PROGETTOAI_MIGLIORATO/
‚îÇ
‚îú‚îÄ‚îÄ config/                 # configurazioni e schema
    ‚îú‚îÄ‚îÄconfig.yaml
    ‚îú‚îÄ‚îÄschema.py
‚îú‚îÄ‚îÄ experiments/            # cartella esperimenti
    ‚îú‚îÄ‚îÄ ..../
        ‚îú‚îÄ‚îÄcheckpoints/    # cartella checkpoint 
        ‚îú‚îÄ‚îÄtensorboard/    # logdir per eseguire tensorboard
‚îú‚îÄ‚îÄ image/                  # immagini esperimenti per report
‚îú‚îÄ‚îÄ models/                 # SimpleCNN + ResNet18
    ‚îú‚îÄ‚îÄsimple_cnn.py
    ‚îú‚îÄ‚îÄresnet18.py
‚îú‚îÄ‚îÄ utils/                  # dataloader, early stopping, seed
    ‚îú‚îÄ‚îÄdataloader.py
    ‚îú‚îÄ‚îÄearly_stopping
    ‚îú‚îÄ‚îÄseed.py              
‚îú‚îÄ‚îÄ scripts/                # script che vengono importati nel main
    ‚îú‚îÄ‚îÄ train.py            # training completo
    ‚îú‚îÄ‚îÄ evaluate.py         # valutazione sul validation/test
    ‚îú‚îÄ‚îÄ predict.py          # predizione su singola immagine
‚îú‚îÄ‚îÄ main.py                 # entry point con modalit√†
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt        # file librerie utilizzate
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

---

## ‚öôÔ∏è Installazione

Assicurati di avere Python 3.9+ installato.

```bash
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Utilizzo
### Avvio del training
```bash
python main.py --mode train
```
### Ripresa del training
```bash
python main.py --mode resume
```
### Valutazione del modello
```bash
python main.py --mode eval
```
### Predizione singola immagine
```bash
python main.py --mode predict
```
Dopo aver eseguito il comando ti verra chiesto:
```
Inserisci il percorso dell'immagine per la predizione:    (es. data/test/cats/cat.40XX.jpg)
```
### TensorBoard
```bash
tensorboard --logdir runs
```
Apri il link nel browser e troverai:
- Loss (train/validation)
- Accuracy
- Matrice di confusione
- Immagini campione
- Architettura del modello

---

## üéØ Motivazioni delle Scelte Progettuali

Questo documento spiega **perch√©** sono state fatte determinate scelte tecniche nel progetto *Dogs vs Cats Classification*.  
Le motivazioni aiutano a comprendere la logica della struttura del codice, le tecniche utilizzate e le decisioni progettuali.

---

## üß† 1. Scelta di implementare un modello SimpleCNN da zero

### Perch√© questa scelta
- Serve come **baseline** semplice per confronti futuri.
- √à un ottimo strumento **didattico** per comprendere il funzionamento delle CNN.
- Permette di capire limiti e problematiche del training da zero.

### Vantaggi
- Semplice da modificare e testare.
- Ottimo per imparare e per debugging.
- Addestramento rapido.

### Limiti
- Prestazioni inferiori ai modelli pre-addestrati.
- Maggiore rischio di overfitting.
- Meno generalizzazione.

---

## üß© 2. Scelta di usare ResNet18 con Transfer Learning

### Perch√© questa scelta
- Modello collaudato, efficiente e bilanciato.
- Il transfer learning sfrutta i pesi di ImageNet.
- Ideale per dataset medio-piccoli come Dogs vs Cats.

### Vantaggi
- Migliore accuratezza e stabilit√†.
- Richiede meno epoche di training.
- Rischio di overfitting ridotto.

### Limiti
- Pi√π pesante del SimpleCNN.
- Meno flessibile da modificare internamente.

---

## ‚è≥ 3. Early Stopping avanzato

### Perch√© implementarlo
- Evita overfitting inutile.
- Riduce il tempo di addestramento.
- Salva automaticamente il miglior modello.

### Caratteristiche implementate
- Monitor su **accuracy** o **loss**.
- `min_delta` per evitare miglioramenti insignificanti.
- `patience` configurabile.
- Supporto per `target_accuracy`.

---

## üíæ 4. Organizzazione dei checkpoint per modello

I checkpoint vengono salvati in cartelle separate:
```
checkpoints/simple_cnn/
checkpoints/resnet18/
```
### Perch√© questa scelta
- Evita confusione tra modelli diversi.
- Permette di riaddestrare o valutare ogni modello individualmente.
- Mantiene il progetto pulito e organizzato.

Ogni checkpoint contiene:
- pesi del modello
- stato dell‚Äôoptimizer
- epoca corrente
- miglior modello (`best_model.pth`)

---

## üîÑ 5. Resume Training automatico

### Perch√© implementarlo
- Utile se il training viene interrotto (crash, terminale chiuso).
- Permette training incrementale.
- Nessuna necessit√† di specificare manualmente i file.

### Funzionamento
- Individua automaticamente l‚Äôultimo checkpoint disponibile.
- Ripristina modello, optimizer, epoca.
- Continua senza perdere informazioni.

---

## ‚öôÔ∏è 6. Configurazione esterna tramite `config.yaml`

### Perch√© un file YAML
- Raccoglie in un solo punto tutti i parametri:
  - batch size  
  - learning rate  
  - modello da usare  
  - early stopping  
  - dimensione immagini  
  - cartella dei dati  
- Evita parametri hard-coded nel codice.
- Maggiore riproducibilit√† degli esperimenti.

### Validazione Pydantic (`schema.py`)
- Controlla automaticamente tipi e valori.
- Intercetta subito configurazioni errate.
- Documenta chiaramente quali campi sono obbligatori.

---

## üìä 7. Uso avanzato di TensorBoard

TensorBoard √® stato integrato per monitorare:

- Loss di training
- Loss di validazione
- Accuracy
- Architettura del modello
- Immagini di esempio
- **Confusion matrix**
- Confronto tra modelli tramite cartelle separate in `runs/`

### Perch√© questa scelta
- Permette di visualizzare immediatamente overfitting.
- Facilita il debug.
- Permette confronti diretti tra modelli.

---

## üìâ 8. Confusion Matrix visualizzata in TensorBoard

### Perch√© implementarla
- L‚Äôaccuracy non basta per valutare le prestazioni.
- La matrice di confusione mostra:
  - dove il modello sbaglia
  - se confonde pi√π spesso cani o gatti
  - eventuali bias nelle predizioni

### Vantaggi
- Facilita la comprensione degli errori.
- Mostra differenze chiare tra SimpleCNN e ResNet18.

---

## üìà Analisi dei risultati degli esperimenti (SimpleCNN vs ResNet18)

Questa sezione riassume l'analisi dei grafici ottenuti con TensorBoard, confrontando gli esperimenti su:
- learning rate
- batch size
- epoche

### Learing Rate: ResNet18 (pretrained, con pesi di ImageNet)
### ‚úÖ Accuracy in Validazione
- LR = 0.0001 [magenta]: molto alta e stabile, il migliore dei tre

- LR = 0.001 [grigio]: discreta ma comunque con valori accettabili

- LR = 0.01 [azzurro]: bassa (0.50 -> 0.75 dopo molte epoche), probabilmente il modello impara con molta difficolta a causa del LR troppo alto

![TensorBoard R_Accuracy screenshot](image/LR/Resnet_accuracy.png)

### üî• Loss in training
- LR = 0.0001 [magenta]: molto bassa e stabile, buona convergenza (diminuisce in modo coerente e si stabilizza su un valore basso non presentando grandi oscillazioni)

- LR = 0.001 [grigio]: situazione intermedia, la convergenza √® abbastanza pulita nonostante ci siano delle oscillazioni (parte alta ma piano piano diminuisce, il modello impara ma non in modo stabile)

- LR = 0.01 [azzurro]: inizialmente molto alta, scende molto lentamente ed √® fortemente instabile

![TensorBoard R_Train loss screenshot](image/LR/Resnet_Train_loss.png)

### ‚ö†Ô∏è Loss in validazione
- LR = 0.0001 [magenta]: valori bassi, nessuna grossa oscillazione e andamento regolare

- LR = 0.001 [grigio]: valore pi√π alto, oscilla molto e non mostra un miglioramento netto

- LR = 0.01 [azzurro]: valori altissimi, peggiora nelle ultime epoche e perde il controllo

![TensorBoard R_Val loss screenshot](image/LR/Resnet_Val_loss.png)

in sintesi:
- 0.0001 -> il modello impara bene e generalizza bene
- 0.001 -> il modello impara ma non in modo ottimale
- 0.01 -> il modello non impara

### Learning Rate: SimpleCNN (modello da zero)
### ‚úÖ Accuracy in Validazione

- LR = 0.0001 [grigio]: sale gradualmente, √® stabile ed √® il miglior LR perch√® impara lentamente ma in modo pulito

- LR = 0.001 [arancione]: sale in modo instabile e poi non migliora pi√π

- LR = 0.01 [verde]: rimane piatta, a quanto pare il modello indovina in modo random e di conseguenza non sta imparando nulla

![TensorBoard S_Accuracy screenshot](image/LR/SimpleCNN_Accuracy.png)

### üî• Loss in training

- LR = 0.0001 [grigio]: scende molto lentamente ma in modo pulito

- LR = 0.001 [arancione]: scende molto rapidamente ma non sta seguendo il trend (la linea arancione pi√π scura)

- LR = 0.01 [verde]: inizialmente altissima, scende pochissimo ma rimane comunque enorme

![TensorBoard S_Train loss screenshot](image/LR/SimpleCNN_Train_loss.png)

### ‚ö†Ô∏è Loss in validazione
- LR = 0.0001 [grigio]: scende inizialmente ma poi risale in modo lento, √® la curva meno instabile e strana

- LR = 0.001 [arancione]: sale in modo molto velocemente, probabilmente non sarebbe in grado di dare previsioni su nuovi dati accurati perch√® fallisce sul set di validazione

- LR = 0.01 [verde]: nessuna capacit√† di apprendimento, √® piatta

![TensorBoard S_Val loss screenshot](image/LR/SimpleCNN_Val_loss.png)

in sintesi:
- 0.0001 -> il modello impara in modo sano ma lento
- 0.001 -> il modello imparara ma nella pratica darebbe problemi
- 0.01 -> il modello non impara

### Batch size: ResNet18 (con il miglior learning rate e con i pesi di ImageNet)

### ‚úÖ Accuracy in Validazione
- BS = 16 [giallo]: andamento irregolare e calo nelle prime epoche (performance peggiori)
- BS = 64 [viola]: abbastanza stabile, non ha troppe oscillazioni, probabilmente il migliore
- BS = 128 [azzurro]: partenza ottima ma leggermente sotto al viola e presenta pi√π oscillazioni

![TensorBoard R_Accuracy screenshot](image/BS/Resnet_Accuracy.png)

### üî• Loss in training
- BS = 16 [giallo]: converge pi√π rapidamente a causa di overfitting
- BS = 64 [viola]: converge abbastanza rapidamente ma ha un comportameno stabile con un andamento pulito e regolare
- BS = 128 [azzurro]: converge pi√π letamente, il modello non impara abbastanza dal training e quindi non migliora in validazione

![TensorBoard R_Train loss screenshot](image/BS/Resnet_Train_loss.png)

### ‚ö†Ô∏è Loss in validazione
- BS = 16 [giallo]: bassa e stabile, nessuna oscillazione importante
- BS = 64 [viola]: andamento accettabile senza troppe oscillazioni
- BS = 128 [azzurro]: andamento oscillante, inizia abbastanza stabile per poi scendere e risalire

![TensorBoard R_Val loss screenshot](image/BS/Resnet_Val_loss.png)

### Batch size: SimpleCNN (con il miglior learning rate)

### ‚úÖ Accuracy in Validazione
- BS = 16 [magenta]: sale rapidamente gi√† dalle prime epoche, ha oscillazioni ma non drammatiche
- BS = 64 [giallo]: va bene ma ha pi√π oscillazioni
- BS = 128 [viola]: stabile ma pi√π basso

![TensorBoard R_Accuracy screenshot](image/BS/SimpleCNN_Accuracy.png)

### üî• Loss in training
- BS = 16 [magenta]: molto bassa, scende rapidamente
- BS = 64 [giallo]: parte alta, pi√π lenta 
- BS = 128 [viola]: parte altissima, scende lentamente e resa comunque elevata dopo un tot di epoche


![TensorBoard R_Train loss screenshot](image/BS/SimpleCNN_Train_loss.png)

### ‚ö†Ô∏è Loss in validazione
- BS = 16 [magenta]: stabile, nessun segnale di overfitting
- BS = 64 [giallo]: pi√π alta, oscilla un po'
- BS = 128 [viola]: altissima, scende ma rimane comunque altissima

![TensorBoard R_Val loss screenshot](image/BS/SimpleCNN_Val_loss.png)
In sintesi:
- BS = 16 -> √® la migliore, equilibrata, migliore accuratezza e generalizzazione ottima
- BS = 64 -> apprende ma lentamente, ha una loss di validazione alta
- BS = 128 -> la loss rimane troppo alta e il learning rate √® troppo basso per un batch di queste dimensioni
---

## ‚úîÔ∏è Conclusione

Le scelte progettuali hanno permesso di ottenere:

- un codice **pulito e modulare**
- un sistema **estendibile**
- un training **controllato e sicuro**
- metriche dettagliate per l‚Äôanalisi
- confronto diretto tra modelli
- riproducibilit√† totale degli esperimenti
