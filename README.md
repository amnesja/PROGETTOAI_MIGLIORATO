# ğŸ¶ğŸ± Dogs vs Cats Classifier â€“ Progetto AI
##Progetto per il corso di Laboratorio di ottimizzazione, intelligenza artificiale e machine learning, realizzato da Naman Bagga il 08/01/2026.
Un progetto completo per la classificazione di immagini di cani e gatti tramite reti neurali convoluzionali (CNN) e transfer learning con ResNet18.  
Include addestramento, validazione, logging avanzato, resume training, predizione e confronto dei modelli.

---

## ğŸ“Œ Caratteristiche principali

### âœ”ï¸ Modelli implementati
- **SimpleCNN** â€“ rete neurale progettata da zero  
- **ResNet18** â€“ rete pre-addestrata tramite transfer learning

### âœ”ï¸ FunzionalitÃ  del sistema
- Dataset loader con trasformazioni e normalizzazione
- Early stopping avanzato (monitor accuracy/loss + target accuracy)
- Resume training automatico dai checkpoint
- Salvataggio automatico:
  - Checkpoint per epoca
  - `best_model.pth`
- TensorBoard logging:
  - Loss / Accuracy
  - Confusion Matrix
  - Architettura del modello
  - Immagini del dataset

### âœ”ï¸ ModalitÃ  operative
- `train` â€“ Addestra il modello
- `eval` â€“ Valuta il modello migliore
- `predict` â€“ Predice classe di un'immagine singola
- `resume` â€“ Riprende il training dallâ€™ultimo checkpoint

---

## ğŸ“‚ Struttura del progetto
```
PROGETTOAI_MIGLIORATO/
â”‚
â”œâ”€â”€ config/                 # configurazioni e schema
    â”œâ”€â”€config.yaml
    â”œâ”€â”€schema.py
â”œâ”€â”€ models/                 # SimpleCNN + ResNet18
    â”œâ”€â”€simple_cnn.py
    â”œâ”€â”€resnet18.py
â”œâ”€â”€ utils/                  # dataloader, early stopping, resume
    â”œâ”€â”€dataloader.py
    â”œâ”€â”€early_stopping
â”œâ”€â”€ checkpoints/            # salvati automaticamente
â”œâ”€â”€ runs/                   # per TensorBoard
â”œâ”€â”€ scripts/                #script che vengono importati nel main
    â”œâ”€â”€ train.py            # training completo
    â”œâ”€â”€ evaluate.py         # valutazione sul validation/test
    â”œâ”€â”€ predict.py          # predizione su singola immagine
â”œâ”€â”€ main.py                 # entry point con modalitÃ 
â”‚
â”œâ”€â”€ requirements.txt        # file librerie utilizzate
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installazione

Assicurati di avere Python 3.9+ installato.

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Utilizzo
### Avvio del training
```bash
python main.py --mode train
```
### Ripresa del training
```bash
python main.py --mode resume
```
### Valutazione del modello
```bash
python main.py --mode eval
```
### Predizione singola immagine
```bash
python main.py --mode predict
```
Dopo aver eseguito il comando ti verra chiesto:
```
Inserisci il percorso dell'immagine per la predizione:    (es. data/test/cats/cat.40XX.jpg)
```
### TensorBoard
```bash
tensorboard --logdir runs
```
Apri il link nel browser e troverai:
- Loss (train/validation)
- Accuracy
- Matrice di confusione
- Immagini campione
- Architettura del modello

---

## ğŸ¯ Motivazioni delle Scelte Progettuali

Questo documento spiega **perchÃ©** sono state fatte determinate scelte tecniche nel progetto *Dogs vs Cats Classification*.  
Le motivazioni aiutano a comprendere la logica della struttura del codice, le tecniche utilizzate e le decisioni progettuali.

---

## ğŸ§  1. Scelta di implementare un modello SimpleCNN da zero

### PerchÃ© questa scelta
- Serve come **baseline** semplice per confronti futuri.
- Ãˆ un ottimo strumento **didattico** per comprendere il funzionamento delle CNN.
- Permette di capire limiti e problematiche del training da zero.

### Vantaggi
- Semplice da modificare e testare.
- Ottimo per imparare e per debugging.
- Addestramento rapido.

### Limiti
- Prestazioni inferiori ai modelli pre-addestrati.
- Maggiore rischio di overfitting.
- Meno generalizzazione.

---

## ğŸ§© 2. Scelta di usare ResNet18 con Transfer Learning

### PerchÃ© questa scelta
- Modello collaudato, efficiente e bilanciato.
- Il transfer learning sfrutta i pesi di ImageNet.
- Ideale per dataset medio-piccoli come Dogs vs Cats.

### Vantaggi
- Migliore accuratezza e stabilitÃ .
- Richiede meno epoche di training.
- Rischio di overfitting ridotto.

### Limiti
- PiÃ¹ pesante del SimpleCNN.
- Meno flessibile da modificare internamente.

---

## â³ 3. Early Stopping avanzato

### PerchÃ© implementarlo
- Evita overfitting inutile.
- Riduce il tempo di addestramento.
- Salva automaticamente il miglior modello.

### Caratteristiche implementate
- Monitor su **accuracy** o **loss**.
- `min_delta` per evitare miglioramenti insignificanti.
- `patience` configurabile.
- Supporto per `target_accuracy`.

---

## ğŸ’¾ 4. Organizzazione dei checkpoint per modello

I checkpoint vengono salvati in cartelle separate:
```
checkpoints/simple_cnn/
checkpoints/resnet18/
```
### PerchÃ© questa scelta
- Evita confusione tra modelli diversi.
- Permette di riaddestrare o valutare ogni modello individualmente.
- Mantiene il progetto pulito e organizzato.

Ogni checkpoint contiene:
- pesi del modello
- stato dellâ€™optimizer
- epoca corrente
- miglior modello (`best_model.pth`)

---

## ğŸ”„ 5. Resume Training automatico

### PerchÃ© implementarlo
- Utile se il training viene interrotto (crash, terminale chiuso).
- Permette training incrementale.
- Nessuna necessitÃ  di specificare manualmente i file.

### Funzionamento
- Individua automaticamente lâ€™ultimo checkpoint disponibile.
- Ripristina modello, optimizer, epoca.
- Continua senza perdere informazioni.

---

## âš™ï¸ 6. Configurazione esterna tramite `config.yaml`

### PerchÃ© un file YAML
- Raccoglie in un solo punto tutti i parametri:
  - batch size  
  - learning rate  
  - modello da usare  
  - early stopping  
  - dimensione immagini  
  - cartella dei dati  
- Evita parametri hard-coded nel codice.
- Maggiore riproducibilitÃ  degli esperimenti.

### Validazione Pydantic (`schema.py`)
- Controlla automaticamente tipi e valori.
- Intercetta subito configurazioni errate.
- Documenta chiaramente quali campi sono obbligatori.

---

## ğŸ“Š 7. Uso avanzato di TensorBoard

TensorBoard Ã¨ stato integrato per monitorare:

- Loss di training
- Loss di validazione
- Accuracy
- Architettura del modello
- Immagini di esempio
- **Confusion matrix**
- Confronto tra modelli tramite cartelle separate in `runs/`

### PerchÃ© questa scelta
- Permette di visualizzare immediatamente overfitting.
- Facilita il debug.
- Permette confronti diretti tra modelli.

---

## ğŸ“‰ 8. Confusion Matrix visualizzata in TensorBoard

### PerchÃ© implementarla
- Lâ€™accuracy non basta per valutare le prestazioni.
- La matrice di confusione mostra:
  - dove il modello sbaglia
  - se confonde piÃ¹ spesso cani o gatti
  - eventuali bias nelle predizioni

### Vantaggi
- Facilita la comprensione degli errori.
- Mostra differenze chiare tra SimpleCNN e ResNet18.

---

## âœ”ï¸ Conclusione

Le scelte progettuali hanno permesso di ottenere:

- un codice **pulito e modulare**
- un sistema **estendibile**
- un training **controllato e sicuro**
- metriche dettagliate per lâ€™analisi
- confronto diretto tra modelli
- riproducibilitÃ  totale degli esperimenti
